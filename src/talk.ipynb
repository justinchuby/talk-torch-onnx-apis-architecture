{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e012217",
   "metadata": {},
   "source": [
    "# PyTorch ONNX Exporter new features and architecture\n",
    "\n",
    "Jan 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c8b41c",
   "metadata": {},
   "source": [
    "![infographics](<pt-onnx-infographics.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee4cda",
   "metadata": {},
   "source": [
    "## `dynamo=True` is the default\n",
    "\n",
    "- The New Default: Starting from PyTorch 2.9, the **`dynamo=True`** option is the **default and recommended** way to export models to ONNX.\n",
    "- Core Shift: It moves away from the older TorchScript-based capture mechanism to a torch.export based modern stack.\n",
    "- Deprecation Plan: While the TorchScript exporter (dynamo=False) is currently usable, it is planned for eventual deprecation in alignment with PyTorch core's handling of TorchScript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f5a6f",
   "metadata": {},
   "source": [
    "## New options in `export()`\n",
    "\n",
    "```py\n",
    "torch.onnx.export(\n",
    "    model, args, kwargs=kwargs,\n",
    "    # New way of expressing dynamic shapes (more examples later)\n",
    "    dynamic_shapes=({0: \"batch\", 1: \"sequence_len\"}),\n",
    "    # dynamic_axes=...,  # Deprecated\n",
    "    dynamo=True,  # Default (2.9)\n",
    "    report=True,  # Creates a markdown report\n",
    "    verify=True,  # Runs onnx runtime on the example\n",
    "    optimize=True, # Runs onnxscript graph optimizations\n",
    ") -> torch.onnx.ONNXProgram\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f989ac",
   "metadata": {},
   "source": [
    "## What happens inside `torch.onnx.export`\n",
    "\n",
    "torch.export() **captures FX** graph\n",
    "-> **translate** and build ONNX IR\n",
    "-> graph **optimization** with ONNX Script\n",
    "\n",
    "Entry point is at: https://github.com/pytorch/pytorch/blob/0ad306cac740eaf2ce582e2bdf097cc61d929a40/torch/onnx/_internal/exporter/_core.py#L1282\n",
    "\n",
    "![diagram](https://raw.githubusercontent.com/justinchuby/diagrams/refs/heads/main/pytorch/torch-export-flow.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FX graph and the ExportedProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde3c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, p_weight: \"f32[10, 10]\", x: \"f32[10, 10]\", y: \"f32[10, 10]\"):\n",
      "             # File: /tmp/ipykernel_246584/1311693341.py:10 in forward, code: a = torch.sin(x)\n",
      "            sin: \"f32[10, 10]\" = torch.ops.aten.sin.default(x);  x = None\n",
      "            \n",
      "             # File: /tmp/ipykernel_246584/1311693341.py:11 in forward, code: a.add_(y)\n",
      "            add_: \"f32[10, 10]\" = torch.ops.aten.add_.Tensor(sin, y);  sin = y = None\n",
      "            \n",
      "             # File: /tmp/ipykernel_246584/1311693341.py:12 in forward, code: return a * self.weight\n",
      "            mul: \"f32[10, 10]\" = torch.ops.aten.mul.Tensor(add_, p_weight);  add_ = p_weight = None\n",
      "            return (mul,)\n",
      "            \n",
      "Graph signature: \n",
      "    # inputs\n",
      "    p_weight: PARAMETER target='weight'\n",
      "    x: USER_INPUT\n",
      "    y: USER_INPUT\n",
      "    \n",
      "    # outputs\n",
      "    mul: USER_OUTPUT\n",
      "    \n",
      "Range constraints: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.export\n",
    "\n",
    "class Mod(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.randn(10, 10))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        a = torch.sin(x)\n",
    "        a.add_(y)\n",
    "        return a * self.weight\n",
    "\n",
    "example_args = (torch.randn(10, 10), torch.randn(10, 10))\n",
    "\n",
    "# Important to set to eval mode before exporting\n",
    "mod = Mod().eval()\n",
    "exported_program: \"ExportedProgram\" = torch.export.export(mod, args=example_args)\n",
    "print(exported_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5dd8edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, p_weight: \"f32[10, 10]\", x: \"f32[10, 10]\", y: \"f32[10, 10]\"):\n",
      "             # File: /tmp/ipykernel_246584/1311693341.py:10 in forward, code: a = torch.sin(x)\n",
      "            sin: \"f32[10, 10]\" = torch.ops.aten.sin.default(x);  x = None\n",
      "            \n",
      "             # File: /tmp/ipykernel_246584/1311693341.py:11 in forward, code: a.add_(y)\n",
      "            add: \"f32[10, 10]\" = torch.ops.aten.add.Tensor(sin, y);  sin = y = None\n",
      "            \n",
      "             # File: /tmp/ipykernel_246584/1311693341.py:12 in forward, code: return a * self.weight\n",
      "            mul: \"f32[10, 10]\" = torch.ops.aten.mul.Tensor(add, p_weight);  add = p_weight = None\n",
      "            return (mul,)\n",
      "            \n",
      "Graph signature: \n",
      "    # inputs\n",
      "    p_weight: PARAMETER target='weight'\n",
      "    x: USER_INPUT\n",
      "    y: USER_INPUT\n",
      "    \n",
      "    # outputs\n",
      "    mul: USER_OUTPUT\n",
      "    \n",
      "Range constraints: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decomposed = exported_program.run_decompositions()\n",
    "print(decomposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf85f2",
   "metadata": {},
   "source": [
    "## Translation to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbef4cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "x input_kind: InputKind.USER_INPUT persistent: None\n",
      "y input_kind: InputKind.USER_INPUT persistent: None\n",
      "p_weight input_kind: InputKind.PARAMETER persistent: None\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "[torch.onnx] Check the ONNX model...\n",
      "[torch.onnx] Check the ONNX model... ✅\n",
      "[torch.onnx] Execute the model with ONNX Runtime...\n",
      "[torch.onnx] Execute the model with ONNX Runtime... ✅\n",
      "[torch.onnx] Verify output accuracy...\n",
      "[torch.onnx] Verify output accuracy... ✅\n",
      "[torch.onnx] Export report has been saved to 'onnx_export_2026-01-05_12-23-00-069243_success.md'.\n",
      "ONNXProgram(\n",
      "    model=\n",
      "        <\n",
      "            ir_version=10,\n",
      "            opset_imports={'': 20},\n",
      "            producer_name='pytorch',\n",
      "            producer_version='2.10.0.dev20251028+cpu',\n",
      "            domain=None,\n",
      "            model_version=None,\n",
      "        >\n",
      "        graph(\n",
      "            name=main_graph,\n",
      "            inputs=(\n",
      "                %\"x\"<FLOAT,[10,10]>,\n",
      "                %\"y\"<FLOAT,[10,10]>\n",
      "            ),\n",
      "            outputs=(\n",
      "                %\"mul\"<FLOAT,[10,10]>\n",
      "            ),\n",
      "            initializers=(\n",
      "                %\"weight\"<FLOAT,[10,10]>{TorchTensor(...)}\n",
      "            ),\n",
      "        ) {\n",
      "            0 |  # node_sin\n",
      "                 %\"sin\"<FLOAT,[10,10]> ⬅️ ::Sin(%\"x\")\n",
      "            1 |  # node_add\n",
      "                 %\"add\"<FLOAT,[10,10]> ⬅️ ::Add(%\"sin\", %\"y\")\n",
      "            2 |  # node_mul\n",
      "                 %\"mul\"<FLOAT,[10,10]> ⬅️ ::Mul(%\"add\", %\"weight\"{...})\n",
      "            return %\"mul\"<FLOAT,[10,10]>\n",
      "        }\n",
      "\n",
      "\n",
      "    ,\n",
      "    exported_program=\n",
      "        ExportedProgram:\n",
      "            class GraphModule(torch.nn.Module):\n",
      "                def forward(self, p_weight: \"f32[10, 10]\", x: \"f32[10, 10]\", y: \"f32[10, 10]\"):\n",
      "                     # File: /tmp/ipykernel_246584/1311693341.py:10 in forward, code: a = torch.sin(x)\n",
      "                    sin: \"f32[10, 10]\" = torch.ops.aten.sin.default(x);  x = None\n",
      "            \n",
      "                     # File: /tmp/ipykernel_246584/1311693341.py:11 in forward, code: a.add_(y)\n",
      "                    add: \"f32[10, 10]\" = torch.ops.aten.add.Tensor(sin, y);  sin = y = None\n",
      "            \n",
      "                     # File: /tmp/ipykernel_246584/1311693341.py:12 in forward, code: return a * self.weight\n",
      "                    mul: \"f32[10, 10]\" = torch.ops.aten.mul.Tensor(add, p_weight);  add = p_weight = None\n",
      "                    return (mul,)\n",
      "            \n",
      "        Graph signature: \n",
      "            # inputs\n",
      "            p_weight: PARAMETER target='weight'\n",
      "            x: USER_INPUT\n",
      "            y: USER_INPUT\n",
      "    \n",
      "            # outputs\n",
      "            mul: USER_OUTPUT\n",
      "    \n",
      "        Range constraints: {}\n",
      "\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onnx_program = torch.onnx.export(exported_program, verify=True, report=True)\n",
    "print(onnx_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "877d62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f18b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading extensions...\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1767644264.603678  247352 port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "Loaded 9 adapters:\n",
      " - TFLite adapter (Flatbuffer)\n",
      " - TFLite adapter (MLIR)\n",
      " - TF adapter (MLIR)\n",
      " - TF adapter (direct)\n",
      " - GraphDef adapter\n",
      " - Pytorch adapter (exported program)\n",
      " - MLIR adapter\n",
      " - ONNX adapter\n",
      " - JSON adapter\n",
      "\n",
      "Starting Model Explorer server at:\n",
      "http://localhost:8080/?data=%7B%22models%22%3A%20%5B%7B%22url%22%3A%20%22/home/justinchu/dev/talk-torch-onnx-apis-architecture/src/model.onnx%22%7D%5D%7D\n",
      "\n",
      "Press Ctrl+C to stop.\n",
      "gio: http://localhost:8080/?data=%7B%22models%22%3A%20%5B%7B%22url%22%3A%20%22/home/justinchu/dev/talk-torch-onnx-apis-architecture/src/model.onnx%22%7D%5D%7D: Operation not supported\n",
      "Stopping server...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!onnxvis model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8ed9e",
   "metadata": {},
   "source": [
    "## Model in `onnx_program.model` is an onnx_ir.Model\n",
    "\n",
    "- You can run any ONNX->ONNX transformation on it.\n",
    "- The exporter by default runs ONNX Script pattern replacement and whole graph optimization. These are robust, in-memory graph passes the team has created\n",
    "- Low memory consumption by sharing tensor data with the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 3 nodes\n",
      "All initializers:\n",
      "  %\"weight\"<FLOAT,[10,10]>{TorchTensor(...)}\n"
     ]
    }
   ],
   "source": [
    "# Explore the IR model\n",
    "\n",
    "model = onnx_program.model\n",
    "print(\"Model has\", len(model.graph), \"nodes\")\n",
    "\n",
    "print(\"All initializers:\")\n",
    "for init in model.graph.initializers.values():\n",
    "    print(\" \", init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb16c985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(model.graph.initializers[\"weight\"].const_value.raw is mod.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e0fe48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TorchTensor<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">FLOAT</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"font-weight: bold\">&gt;(</span>Parameter containing: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0907e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5376e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.3582e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.7708e-01</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.9148e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.8229e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1517e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.6128e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1214e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.3366e-01</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.7739e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5673e-01</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.2370e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.3048e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.7112e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5006e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.7150e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.0543e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-7.0478e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1714e+00</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.7062e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1843e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.0908e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0033e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4659e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8297e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.3489e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1888e+00</span>,  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2808e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8380e+00</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.8664e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.6764e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8.6129e-02</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0419e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.8287e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.8274e-01</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.8635e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.5279e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1301e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.4622e-01</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.9503e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1259e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.4191e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1867e+00</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.9510e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0607e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.9146e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3685e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0492e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.1548e-02</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.1088e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.8937e-01</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.9615e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.8070e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.8016e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4684e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.7752e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.9450e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.9617e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.8532e-01</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.0937e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3652e-02</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8041e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.4031e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.9256e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.7330e+00</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.1820e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.3262e-01</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.4171e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.4438e-01</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.8903e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.2425e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.6874e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.3434e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.6576e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1994e-01</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-9.7236e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.6537e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.6553e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4067e-01</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.2247e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.8754e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.6873e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3509e+00</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.4623e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1999e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.1742e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.9808e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.4438e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0525e+00</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.4098e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.8164e-01</span>,  \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5952e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.4772e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3845e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4168e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1702e-01</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.0295e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0441e+00</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.4880e-01</span><span style=\"font-weight: bold\">]]</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">requires_grad</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'weight'</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "Min: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.4031074047088623</span>, Max: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0525074005126953</span>, NaN count: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, Inf count: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "Sparsity <span style=\"font-weight: bold\">(</span>abs&lt;<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-06</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>\n",
       "Histogram:\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> ┼                                                ╭╮\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> ┤                                                ││\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> ┤                                                ││\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> ┤                                ╭╮     ╭╮    ╭╮ ││     ╭╮\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> ┤                         ╭╮     │╰╮   ╭╯│    ││ ││     ││      ╭╮\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> ┤           ╭╮        ╭╮╭─╯│  ╭──╯ │╭──╯ ╰─╮ ╭╯│ │╰╮ ╭╮ │╰╮ ╭─╮╭╯│         ╭╮\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> ┤           ││        │││  │  │    ││      │ │ │ │ │ ││ │ │ │ ││ │         ││\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> ┼╮╭╮    ╭──╮││╭──╮╭╮ ╭╯╰╯  │  │    ╰╯      ╰╮│ ╰─╯ ╰─╯╰╮│ ╰─╯ ││ │╭╮╭─╮    │╰─╮╭\n",
       "       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> ┤╰╯╰────╯  ╰╯╰╯  ╰╯╰─╯     ╰──╯             ╰╯         ╰╯     ╰╯ ╰╯╰╯ ╰────╯  ╰╯\n",
       "    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.4031</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.9575</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5120</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0107</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5652</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0639</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3817</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8272</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2171</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6626</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TorchTensor\u001b[1m<\u001b[0m\u001b[1;95mFLOAT\u001b[0m\u001b[39m,\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[39m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1m>\u001b[0m\u001b[1m(\u001b[0mParameter containing: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.0907e+00\u001b[0m, \u001b[1;36m-1.5376e+00\u001b[0m,  \u001b[1;36m8.3582e-01\u001b[0m,  \u001b[1;36m3.7708e-01\u001b[0m, \n",
       "\u001b[1;36m-1.9148e+00\u001b[0m, \u001b[1;36m-1.8229e-03\u001b[0m, \u001b[1;36m-1.1517e+00\u001b[0m, \u001b[1;36m-1.6128e+00\u001b[0m,  \u001b[1;36m1.1214e+00\u001b[0m,  \u001b[1;36m7.3366e-01\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m \u001b[1;36m2.7739e-01\u001b[0m, \u001b[1;36m-1.5673e-01\u001b[0m, \n",
       "\u001b[1;36m-2.2370e+00\u001b[0m,  \u001b[1;36m1.3048e-01\u001b[0m, \u001b[1;36m-1.7112e+00\u001b[0m, \u001b[1;36m3.5006e-01\u001b[0m, \u001b[1;36m-3.7150e-01\u001b[0m, \u001b[1;36m-9.0543e-01\u001b[0m, \u001b[1;36m-7.0478e-01\u001b[0m,  \u001b[1;36m1.1714e+00\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[1m[\u001b[0m\u001b[1;36m-2.7062e-01\u001b[0m,  \u001b[1;36m1.1843e+00\u001b[0m,  \u001b[1;36m6.0908e-01\u001b[0m,  \u001b[1;36m2.0033e-01\u001b[0m, \u001b[1;36m-1.4659e+00\u001b[0m, \u001b[1;36m1.8297e+00\u001b[0m,  \u001b[1;36m4.3489e-01\u001b[0m,  \u001b[1;36m1.1888e+00\u001b[0m,  \n",
       "\u001b[1;36m1.2808e+00\u001b[0m,  \u001b[1;36m1.8380e+00\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m \u001b[1;36m7.8664e-01\u001b[0m, \u001b[1;36m-4.6764e-01\u001b[0m, \u001b[1;36m-8.6129e-02\u001b[0m,  \u001b[1;36m1.0419e+00\u001b[0m, \u001b[1;36m-1.8287e+00\u001b[0m, \u001b[1;36m-2.8274e-01\u001b[0m, \n",
       "\u001b[1;36m-1.8635e+00\u001b[0m, \u001b[1;36m-6.5279e-01\u001b[0m, \u001b[1;36m-1.1301e+00\u001b[0m, \u001b[1;36m-9.4622e-01\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m-1.9503e-01\u001b[0m,  \u001b[1;36m1.1259e+00\u001b[0m, \u001b[1;36m-5.4191e-01\u001b[0m, \u001b[1;36m-1.1867e+00\u001b[0m, \n",
       "\u001b[1;36m-3.9510e-01\u001b[0m, \u001b[1;36m-1.0607e+00\u001b[0m, \u001b[1;36m-9.9146e-01\u001b[0m,  \u001b[1;36m2.3685e-01\u001b[0m,  \u001b[1;36m1.0492e+00\u001b[0m, \u001b[1;36m-2.1548e-02\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m \u001b[1;36m4.1088e-01\u001b[0m,  \u001b[1;36m5.8937e-01\u001b[0m, \n",
       "\u001b[1;36m-5.9615e-01\u001b[0m, \u001b[1;36m-4.8070e-01\u001b[0m,  \u001b[1;36m7.8016e-01\u001b[0m, \u001b[1;36m1.4684e+00\u001b[0m, \u001b[1;36m-1.7752e-01\u001b[0m, \u001b[1;36m-6.9450e-01\u001b[0m,  \u001b[1;36m1.9617e-01\u001b[0m,  \u001b[1;36m9.8532e-01\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[1m[\u001b[0m\u001b[1;36m-5.0937e-01\u001b[0m, \u001b[1;36m-1.3652e-02\u001b[0m,  \u001b[1;36m1.8041e+00\u001b[0m, \u001b[1;36m-2.4031e+00\u001b[0m,  \u001b[1;36m1.9256e+00\u001b[0m, \u001b[1;36m-1.7330e+00\u001b[0m, \u001b[1;36m-9.1820e-01\u001b[0m, \u001b[1;36m-5.3262e-01\u001b[0m, \n",
       "\u001b[1;36m-3.4171e-01\u001b[0m, \u001b[1;36m-5.4438e-01\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m \u001b[1;36m1.8903e-01\u001b[0m,  \u001b[1;36m5.2425e-01\u001b[0m, \u001b[1;36m-6.6874e-01\u001b[0m,  \u001b[1;36m9.3434e-01\u001b[0m,  \u001b[1;36m4.6576e-01\u001b[0m, \u001b[1;36m1.1994e-01\u001b[0m, \n",
       "\u001b[1;36m-9.7236e-01\u001b[0m,  \u001b[1;36m3.6537e-01\u001b[0m,  \u001b[1;36m7.6553e-01\u001b[0m, \u001b[1;36m-1.4067e-01\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m-1.2247e-01\u001b[0m, \u001b[1;36m-1.8754e-01\u001b[0m, \u001b[1;36m-5.6873e-01\u001b[0m, \u001b[1;36m-1.3509e+00\u001b[0m, \n",
       "\u001b[1;36m-4.4623e-01\u001b[0m, \u001b[1;36m-1.1999e-01\u001b[0m,  \u001b[1;36m7.1742e-01\u001b[0m, \u001b[1;36m-2.9808e-01\u001b[0m, \u001b[1;36m-5.4438e-01\u001b[0m,  \u001b[1;36m2.0525e+00\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m \u001b[1;36m1.4098e+00\u001b[0m,  \u001b[1;36m3.8164e-01\u001b[0m,  \n",
       "\u001b[1;36m1.5952e-01\u001b[0m,  \u001b[1;36m7.4772e-01\u001b[0m,  \u001b[1;36m3.3845e-01\u001b[0m, \u001b[1;36m9.4168e-01\u001b[0m, \u001b[1;36m-1.1702e-01\u001b[0m,  \u001b[1;36m6.0295e-01\u001b[0m, \u001b[1;36m-1.0441e+00\u001b[0m,  \u001b[1;36m3.4880e-01\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[33mrequires_grad\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'weight'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n",
       "Min: \u001b[1;36m-2.4031074047088623\u001b[0m, Max: \u001b[1;36m2.0525074005126953\u001b[0m, NaN count: \u001b[1;36m0\u001b[0m, Inf count: \u001b[1;36m0\u001b[0m\n",
       "Sparsity \u001b[1m(\u001b[0mabs<\u001b[1;36m1e-06\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m0.00\u001b[0m\n",
       "Histogram:\n",
       "       \u001b[1;36m6\u001b[0m ┼                                                ╭╮\n",
       "       \u001b[1;36m5\u001b[0m ┤                                                ││\n",
       "       \u001b[1;36m4\u001b[0m ┤                                                ││\n",
       "       \u001b[1;36m4\u001b[0m ┤                                ╭╮     ╭╮    ╭╮ ││     ╭╮\n",
       "       \u001b[1;36m3\u001b[0m ┤                         ╭╮     │╰╮   ╭╯│    ││ ││     ││      ╭╮\n",
       "       \u001b[1;36m2\u001b[0m ┤           ╭╮        ╭╮╭─╯│  ╭──╯ │╭──╯ ╰─╮ ╭╯│ │╰╮ ╭╮ │╰╮ ╭─╮╭╯│         ╭╮\n",
       "       \u001b[1;36m2\u001b[0m ┤           ││        │││  │  │    ││      │ │ │ │ │ ││ │ │ │ ││ │         ││\n",
       "       \u001b[1;36m1\u001b[0m ┼╮╭╮    ╭──╮││╭──╮╭╮ ╭╯╰╯  │  │    ╰╯      ╰╮│ ╰─╯ ╰─╯╰╮│ ╰─╯ ││ │╭╮╭─╮    │╰─╮╭\n",
       "       \u001b[1;36m0\u001b[0m ┤╰╯╰────╯  ╰╯╰╯  ╰╯╰─╯     ╰──╯             ╰╯         ╰╯     ╰╯ ╰╯╰╯ ╰────╯  ╰╯\n",
       "    \u001b[1;36m-2.4031\u001b[0m  \u001b[1;36m-1.9575\u001b[0m  \u001b[1;36m-1.5120\u001b[0m  \u001b[1;36m-1.0107\u001b[0m  \u001b[1;36m-0.5652\u001b[0m  \u001b[1;36m-0.0639\u001b[0m  \u001b[1;36m0.3817\u001b[0m  \u001b[1;36m0.8272\u001b[0m  \u001b[1;36m1.2171\u001b[0m  \u001b[1;36m1.6626\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.graph.initializers[\"weight\"].const_value.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9beb92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All users of the initializer: (Usage(node=Node(name='node_mul', domain='', op_type='Mul', inputs=(SymbolicTensor(name='add', type=Tensor(FLOAT), shape=Shape([10, 10]), producer='node_add', index=0), SymbolicTensor(name='weight', type=Tensor(FLOAT), shape=Shape([10, 10]), const_value={TorchTensor(...)})), attributes={}, overload='', outputs=(SymbolicTensor(name='mul', type=Tensor(FLOAT), shape=Shape([10, 10]), producer='node_mul', index=0),), version=20, doc_string=None), idx=1),)\n"
     ]
    }
   ],
   "source": [
    "print(\"All users of the initializer:\", model.graph.initializers[\"weight\"].uses())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97327cfa",
   "metadata": {},
   "source": [
    "## Multiple ways to represent dynamic shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb3199",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
